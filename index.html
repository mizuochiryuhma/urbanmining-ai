<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8" />
    <title>都市鉱山AI判定</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <style>
      body {
        font-family: "Segoe UI", "Hiragino Kaku Gothic ProN", sans-serif;
        text-align: center;
        margin-top: 30px;
        background-color: #fafafa;
      }
      h1 {
        color: #333;
      }
      button {
        margin: 5px;
        padding: 10px 20px;
        border-radius: 8px;
        border: none;
        background-color: #0078d7;
        color: white;
        cursor: pointer;
      }
      button:hover {
        background-color: #005fa3;
      }
      #webcam-container {
        margin-top: 20px;
      }
    </style>
  </head>

  <body>
    <h1>都市鉱山AI判定アプリ</h1>
    <p>カメラに映した電子廃材をAIが分類します</p>

    <button type="button" onclick="init()">AI起動</button>
    <button type="button" onclick="stopAI()">AI終了</button>
    <button onclick="testSpeak()">音声テスト</button>

    <div id="webcam-container"></div>
    <h2 id="label">待機中…</h2>

    <script>
      const URL = "https://teachablemachine.withgoogle.com/models/【あなたのモデルID】/";
      let model, webcam, maxPredictions;
      let stopFlag = false;

      async function init() {
        stopFlag = false;
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        model = await tmImage.load(modelURL, metadataURL);
        webcam = new tmImage.Webcam(200, 200, true);
        await webcam.setup();
        await webcam.play();
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        maxPredictions = model.getTotalClasses();

        speak("AIを起動しました");
        window.requestAnimationFrame(loop);
      }

      async function loop() {
        if (stopFlag || !webcam) return;
        webcam.update();
        await predict();
        window.requestAnimationFrame(loop);
      }

      async function predict() {
        const prediction = await model.predict(webcam.canvas);
        let highestProb = 0;
        let bestLabel = "";
        for (let i = 0; i < prediction.length; i++) {
          if (prediction[i].probability > highestProb) {
            highestProb = prediction[i].probability;
            bestLabel = prediction[i].className;
          }
        }

        const result = document.getElementById("label");
        result.innerText = bestLabel + "（" + (highestProb * 100).toFixed(1) + "%）";

        if (highestProb > 0.8) {
          if (bestLabel === "高銅") {
            speak("宝のやま～");
          } else if (bestLabel === "低銅") {
            speak("やめとき～");
          } else {
            speak("ちょっとよくわからない");
          }
        }
      }

      function speak(text) {
        const synth = window.speechSynthesis;
        if (synth && !synth.speaking) {
          const utter = new SpeechSynthesisUtterance(text);
          utter.lang = "ja-JP";
          setTimeout(() => synth.speak(utter), 100);
        }
      }

      function testSpeak() {
        const synth = window.speechSynthesis;
        if (!synth) {
          alert("Speech Synthesis API 非対応");
          return;
        }
        const utter = new SpeechSynthesisUtterance("テストです、よろしくお願いいたします。");
        utter.lang = "ja-JP";
        synth.speak(utter);
      }

      async function stopAI() {
        stopFlag = true;
        window.speechSynthesis.cancel();
        if (webcam) {
          await webcam.stop();
          if (webcam.canvas && webcam.canvas.parentNode) {
            webcam.canvas.parentNode.removeChild(webcam.canvas);
          }
          webcam = null;
        }
        setTimeout(() => {
          document.getElementById("label").innerText = "待機中…";
        }, 200);
        speak("AIを終了します");
      }
    </script>
  </body>
</html>
